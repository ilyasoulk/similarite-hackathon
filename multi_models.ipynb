{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":46697,"sourceType":"datasetVersion","datasetId":31559}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch # Check if CUDA is available\nimport torchvision\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\nfrom torch.utils.data import DataLoader, Subset\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport seaborn as sns\nimport time\n\n\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"Using GPU:\", torch.cuda.get_device_name(0))\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, using CPU instead.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-24T20:52:22.603630Z","iopub.execute_input":"2024-04-24T20:52:22.604060Z","iopub.status.idle":"2024-04-24T20:52:32.158613Z","shell.execute_reply.started":"2024-04-24T20:52:22.604024Z","shell.execute_reply":"2024-04-24T20:52:32.157414Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Using GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"!cp -r /kaggle/input/stanford-car-dataset-by-classes-folder/car_data/ .","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:52:53.316592Z","iopub.execute_input":"2024-04-24T20:52:53.317189Z","iopub.status.idle":"2024-04-24T20:54:39.243633Z","shell.execute_reply.started":"2024-04-24T20:52:53.317155Z","shell.execute_reply":"2024-04-24T20:54:39.242174Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\n\ndef reorganize_dataset(source_dir, target_dir):\n    \"\"\"\n    Reorganize the dataset by car brand.\n\n    Parameters:\n    source_dir (str): The directory where the current dataset is stored.\n    target_dir (str): The directory where the reorganized dataset will be stored.\n    \"\"\"\n    # Create the target directory if it doesn't exist\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    # List all files in the source directory\n    directories = [d for d in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, d))]\n\n    # Process each file\n    for directory in directories:\n        # Extract brand name (assuming it's the first word of the file name)\n        brand = directory.split(' ')[0]\n\n        # Create a directory for the brand if it doesn't exist\n        brand_dir = os.path.join(target_dir, brand)\n        if not os.path.exists(brand_dir):\n            os.makedirs(brand_dir)\n            \n        current_dir_path = os.path.join(source_dir, directory)\n        # Move each file in the current directory to the brand directory\n        for file in os.listdir(current_dir_path):\n            src_path = os.path.join(current_dir_path, file)\n            dst_path = os.path.join(brand_dir, file)\n            shutil.move(src_path, dst_path)\n            print(f\"Moved {file} from {current_dir_path} to {brand_dir}\")\n        \n        \nsource_train = 'car_data/car_data/train'\nsource_test = 'car_data/car_data/test'\nreorganize_dataset(source_train, 'train')\nreorganize_dataset(source_test, 'test')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 32\n\ntransform = transforms.Compose([\n    transforms.Resize((400, 400)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ntest_tfms = transforms.Compose([\n    transforms.Resize((400, 400)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\n\ntrain_set = datasets.ImageFolder('train', transform=transform)\ntest_set = datasets.ImageFolder('test', transform=test_tfms)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:56:07.165260Z","iopub.execute_input":"2024-04-24T20:56:07.165938Z","iopub.status.idle":"2024-04-24T20:56:07.258285Z","shell.execute_reply.started":"2024-04-24T20:56:07.165906Z","shell.execute_reply":"2024-04-24T20:56:07.257298Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"len(train_set.classes)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:56:12.739238Z","iopub.execute_input":"2024-04-24T20:56:12.740067Z","iopub.status.idle":"2024-04-24T20:56:12.748295Z","shell.execute_reply.started":"2024-04-24T20:56:12.740032Z","shell.execute_reply":"2024-04-24T20:56:12.747196Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"49"},"metadata":{}}]},{"cell_type":"code","source":"train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\ntest_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:56:14.568010Z","iopub.execute_input":"2024-04-24T20:56:14.568440Z","iopub.status.idle":"2024-04-24T20:56:14.574564Z","shell.execute_reply.started":"2024-04-24T20:56:14.568408Z","shell.execute_reply":"2024-04-24T20:56:14.573455Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, n_epochs = 5):\n    \n    losses = []\n    accuracies = []\n    test_accuracies = []\n    # set the model to train mode initially\n    model.train()\n    model=model.to('cuda')\n    for epoch in range(n_epochs):\n        since = time.time()\n        running_loss = 0.0\n        running_correct = 0.0\n        for i, data in enumerate(train_loader, 0):\n\n            # get the inputs and assign them to cuda\n            inputs, labels = data\n            \n            inputs, labels = inputs.cuda(), labels.cuda()\n            optimizer.zero_grad()\n             # forward + backward + optimize\n                \n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            # calculate the loss/acc later\n            running_loss += loss.item()\n            running_correct += (labels==predicted).sum().item()\n\n        epoch_duration = time.time()-since\n        epoch_loss = running_loss/len(train_loader)\n        epoch_acc = 100/BATCH_SIZE*running_correct/len(train_loader)\n        print(\"Epoch %s, duration: %d s, loss: %.4f, acc: %.4f\" % (epoch+1, epoch_duration, epoch_loss, epoch_acc))\n        \n        losses.append(epoch_loss)\n        accuracies.append(epoch_acc)\n        model.eval()\n        test_acc = eval_model(model)\n        test_accuracies.append(test_acc)\n        \n        # re-set the model to train mode after validating\n        model.train()\n        scheduler.step(test_acc)\n        since = time.time()\n    print('Finished Training')\n    return model, losses, accuracies, test_accuracies\n\n\ndef eval_model(model):\n    correct = 0.0\n    total = 0.0\n    with torch.no_grad():\n        for i, data in enumerate(test_loader, 0):\n            images, labels = data\n            \n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            \n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n        test_acc = 100.0 * correct / total\n    print('Accuracy of the network on the test images: %d %%' % (\n        test_acc))\n    return test_acc","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:56:16.424105Z","iopub.execute_input":"2024-04-24T20:56:16.424780Z","iopub.status.idle":"2024-04-24T20:56:16.441059Z","shell.execute_reply.started":"2024-04-24T20:56:16.424749Z","shell.execute_reply":"2024-04-24T20:56:16.439727Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torchvision.models as models\n\nmodel = models.resnet18(pretrained=True)\n\nnum_ftrs = model.fc.in_features\nmodel.fc = torch.nn.Linear(num_ftrs, 49)\nmodel.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\nlrscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:56:18.979732Z","iopub.execute_input":"2024-04-24T20:56:18.980171Z","iopub.status.idle":"2024-04-24T20:56:19.966001Z","shell.execute_reply.started":"2024-04-24T20:56:18.980138Z","shell.execute_reply":"2024-04-24T20:56:19.965028Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 119MB/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"model, training_losses, training_accs, test_accs = train_model(model, criterion, optimizer, lrscheduler, n_epochs=10)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T20:56:24.038850Z","iopub.execute_input":"2024-04-24T20:56:24.039250Z","iopub.status.idle":"2024-04-24T21:14:03.100522Z","shell.execute_reply.started":"2024-04-24T20:56:24.039222Z","shell.execute_reply":"2024-04-24T21:14:03.098925Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1, duration: 58 s, loss: 2.3480, acc: 38.8971\nAccuracy of the network on the test images: 59 %\nEpoch 2, duration: 57 s, loss: 1.0537, acc: 70.3309\nAccuracy of the network on the test images: 64 %\nEpoch 3, duration: 57 s, loss: 0.6012, acc: 82.7574\nAccuracy of the network on the test images: 68 %\nEpoch 4, duration: 58 s, loss: 0.3748, acc: 89.2279\nAccuracy of the network on the test images: 78 %\nEpoch 5, duration: 57 s, loss: 0.2533, acc: 92.4632\nAccuracy of the network on the test images: 84 %\nEpoch 6, duration: 57 s, loss: 0.1018, acc: 97.4877\nAccuracy of the network on the test images: 91 %\nEpoch 7, duration: 57 s, loss: 0.0637, acc: 98.5539\nAccuracy of the network on the test images: 91 %\nEpoch 8, duration: 57 s, loss: 0.0487, acc: 98.9951\nAccuracy of the network on the test images: 92 %\nEpoch 9, duration: 57 s, loss: 0.0378, acc: 99.3995\nAccuracy of the network on the test images: 92 %\nEpoch 10, duration: 58 s, loss: 0.0342, acc: 99.5098\nAccuracy of the network on the test images: 92 %\nFinished Training\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model, 'brand_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:14:20.092606Z","iopub.execute_input":"2024-04-24T21:14:20.093101Z","iopub.status.idle":"2024-04-24T21:14:20.212775Z","shell.execute_reply.started":"2024-04-24T21:14:20.093051Z","shell.execute_reply":"2024-04-24T21:14:20.211628Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!cp -r /kaggle/input/stanford-car-dataset-by-classes-folder/car_data/ .","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:14:24.666782Z","iopub.execute_input":"2024-04-24T21:14:24.667222Z","iopub.status.idle":"2024-04-24T21:14:44.175687Z","shell.execute_reply.started":"2024-04-24T21:14:24.667190Z","shell.execute_reply":"2024-04-24T21:14:44.174183Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def reorganize_dataset_chevrolet(source_dir, target_dir):\n    \"\"\"\n    Reorganize the dataset by car brand.\n\n    Parameters:\n    source_dir (str): The directory where the current dataset is stored.\n    target_dir (str): The directory where the reorganized dataset will be stored.\n    \"\"\"\n    # Create the target directory if it doesn't exist\n    if not os.path.exists(target_dir):\n        os.makedirs(target_dir)\n\n    # List all files in the source directory\n    directories = [d for d in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, d))]\n\n    # Process each file\n    for directory in directories:\n        # Extract brand name (assuming it's the first word of the file name)\n        brand = directory.split(' ')[0]\n        if brand == 'Chevrolet':\n        # Create a directory for the brand if it doesn't exist\n            brand_dir = os.path.join(target_dir, directory)\n            if not os.path.exists(brand_dir):\n                os.makedirs(brand_dir)\n            \n            current_dir_path = os.path.join(source_dir, directory)\n            print(directory)\n            # Move each file in the current directory to the brand directory\n            for file in os.listdir(current_dir_path):\n                src_path = os.path.join(current_dir_path, file)\n                dst_path = os.path.join(brand_dir, file)\n                shutil.move(src_path, dst_path)\n                print(f\"Moved {file} from {current_dir_path} to {brand_dir}\")\n\n        \nsource_train = 'car_data/car_data/train'\nsource_test = 'car_data/car_data/test'\nreorganize_dataset_chevrolet(source_train, 'train_chevrolet')\nreorganize_dataset_chevrolet(source_test, 'test_chevrolet')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_chevrolet_set = datasets.ImageFolder('train_chevrolet', transform=transform)\ntest_chevrolet_set = datasets.ImageFolder('test_chevrolet', transform=test_tfms)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:15:19.815166Z","iopub.execute_input":"2024-04-24T21:15:19.815584Z","iopub.status.idle":"2024-04-24T21:15:19.834771Z","shell.execute_reply.started":"2024-04-24T21:15:19.815549Z","shell.execute_reply":"2024-04-24T21:15:19.833469Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"len(train_chevrolet_set.classes)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:15:22.047697Z","iopub.execute_input":"2024-04-24T21:15:22.048128Z","iopub.status.idle":"2024-04-24T21:15:22.056951Z","shell.execute_reply.started":"2024-04-24T21:15:22.048095Z","shell.execute_reply":"2024-04-24T21:15:22.055882Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"22"},"metadata":{}}]},{"cell_type":"code","source":"train_loader = DataLoader(train_chevrolet_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\ntest_loader = DataLoader(test_chevrolet_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:15:33.047362Z","iopub.execute_input":"2024-04-24T21:15:33.048182Z","iopub.status.idle":"2024-04-24T21:15:33.054296Z","shell.execute_reply.started":"2024-04-24T21:15:33.048143Z","shell.execute_reply":"2024-04-24T21:15:33.053038Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model_chevrolet = models.resnet18(pretrained=True)\n\nnum_ftrs = model_chevrolet.fc.in_features\nmodel_chevrolet.fc = torch.nn.Linear(num_ftrs, 22)\nmodel_chevrolet.to(device)\ncriterion_2 = nn.CrossEntropyLoss()\noptimizer_2 = optim.SGD(model_chevrolet.parameters(), lr=0.01, momentum=0.9)\nlrscheduler_2 = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=3, threshold = 0.9)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:15:51.460816Z","iopub.execute_input":"2024-04-24T21:15:51.461770Z","iopub.status.idle":"2024-04-24T21:15:51.786148Z","shell.execute_reply.started":"2024-04-24T21:15:51.461734Z","shell.execute_reply":"2024-04-24T21:15:51.784982Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model_chevrolet, training_losses_chevrolet, training_accs_chevrolet, test_accs_chevrolet = train_model(model_chevrolet, criterion_2, optimizer_2, lrscheduler_2, n_epochs=20)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:16:14.894453Z","iopub.execute_input":"2024-04-24T21:16:14.895248Z","iopub.status.idle":"2024-04-24T21:20:48.543438Z","shell.execute_reply.started":"2024-04-24T21:16:14.895213Z","shell.execute_reply":"2024-04-24T21:20:48.542138Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1, duration: 7 s, loss: 2.9414, acc: 12.7155\nAccuracy of the network on the test images: 22 %\nEpoch 2, duration: 7 s, loss: 1.4554, acc: 51.4009\nAccuracy of the network on the test images: 42 %\nEpoch 3, duration: 7 s, loss: 0.7605, acc: 74.3534\nAccuracy of the network on the test images: 66 %\nEpoch 4, duration: 7 s, loss: 0.4161, acc: 85.3448\nAccuracy of the network on the test images: 70 %\nEpoch 5, duration: 7 s, loss: 0.2989, acc: 89.2241\nAccuracy of the network on the test images: 69 %\nEpoch 6, duration: 7 s, loss: 0.2096, acc: 92.3491\nAccuracy of the network on the test images: 75 %\nEpoch 7, duration: 7 s, loss: 0.1619, acc: 93.5345\nAccuracy of the network on the test images: 77 %\nEpoch 8, duration: 7 s, loss: 0.1106, acc: 95.0431\nAccuracy of the network on the test images: 76 %\nEpoch 9, duration: 7 s, loss: 0.1126, acc: 93.7500\nAccuracy of the network on the test images: 72 %\nEpoch 10, duration: 7 s, loss: 0.0781, acc: 95.9052\nAccuracy of the network on the test images: 77 %\nEpoch 11, duration: 7 s, loss: 0.0431, acc: 96.8750\nAccuracy of the network on the test images: 80 %\nEpoch 12, duration: 7 s, loss: 0.0459, acc: 96.8750\nAccuracy of the network on the test images: 79 %\nEpoch 13, duration: 7 s, loss: 0.0822, acc: 94.9353\nAccuracy of the network on the test images: 74 %\nEpoch 14, duration: 7 s, loss: 0.0593, acc: 95.9052\nAccuracy of the network on the test images: 78 %\nEpoch 15, duration: 7 s, loss: 0.0369, acc: 97.0905\nAccuracy of the network on the test images: 79 %\nEpoch 16, duration: 7 s, loss: 0.0509, acc: 96.4440\nAccuracy of the network on the test images: 80 %\nEpoch 17, duration: 7 s, loss: 0.0289, acc: 97.0905\nAccuracy of the network on the test images: 81 %\nEpoch 18, duration: 7 s, loss: 0.0176, acc: 97.1983\nAccuracy of the network on the test images: 80 %\nEpoch 19, duration: 7 s, loss: 0.0132, acc: 97.0905\nAccuracy of the network on the test images: 81 %\nEpoch 20, duration: 7 s, loss: 0.0120, acc: 97.4138\nAccuracy of the network on the test images: 81 %\nFinished Training\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model_chevrolet, 'chevrolet_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-04-24T21:21:16.189914Z","iopub.execute_input":"2024-04-24T21:21:16.190335Z","iopub.status.idle":"2024-04-24T21:21:16.294975Z","shell.execute_reply.started":"2024-04-24T21:21:16.190301Z","shell.execute_reply":"2024-04-24T21:21:16.293939Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}